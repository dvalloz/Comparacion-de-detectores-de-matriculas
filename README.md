# Comparaci√≥n de Detectores y Reconocedores de Matr√≠culas Vehiculares üöóüì∏
Autor del trabajo: David Valls Lozano



Este proyecto presenta un estudio comparativo de diversos enfoques para la **detecci√≥n y reconocimiento autom√°tico de matr√≠culas vehiculares**, integrando tanto **m√©todos cl√°sicos de visi√≥n por computador** como **modelos modernos de aprendizaje profundo**.  
El objetivo principal es evaluar la eficacia, precisi√≥n y eficiencia temporal de cada t√©cnica en distintas condiciones visuales, con el prop√≥sito de determinar qu√© m√©todo ofrece un rendimiento m√°s robusto y generalizable.

## ‚öôÔ∏è Tecnolog√≠as Utilizadas

- **Lenguaje:** Python 3.10+
- **Bibliotecas principales:**  
  - OpenCV  
  - EasyOCR  
  - Ultralytics YOLOv8  
  - PyTorch  
  - NumPy, Pandas, Matplotlib 
---

## üß† Introducci√≥n

La identificaci√≥n autom√°tica de matr√≠culas constituye una aplicaci√≥n esencial en √°mbitos como el control de acceso vehicular, la gesti√≥n de tr√°fico, la seguridad urbana y los sistemas de peaje automatizados.  
A lo largo de los a√±os, las t√©cnicas empleadas han evolucionado desde algoritmos basados en procesamiento morfol√≥gico hasta arquitecturas profundas de redes neuronales convolucionales (CNN).

Este trabajo implementa y compara cuatro m√©todos representativos, con el fin de establecer un marco experimental reproducible y contrastar los resultados bajo m√©tricas objetivas.

 1.**Detecci√≥n por contornos (OpenCV)**  
   M√©todo tradicional que utiliza operaciones morfol√≥gicas, umbralizaci√≥n adaptativa y filtrado por proporciones geom√©tricas para localizar regiones candidatas a matr√≠culas.  
   Es una t√©cnica eficiente, pero sensible a variaciones de iluminaci√≥n y √°ngulos de captura.

Utiliza como paquetes principales OpenCV y imutils para la mayor√≠a de las funciones del m√©todo, junto a otros paquetes b√°sicos.




    
![png](notebook_files/output_4_0.png)
    



    
![png](notebook_files/output_4_1.png)
    



    
![png](notebook_files/output_4_2.png)
    



    
![png](notebook_files/output_4_3.png)
    



    
![png](notebook_files/output_4_4.png)
    
    

    
    



2. **Detector con EasyOCR**
   Sistema OCR preentrenado capaz de detectar y reconocer texto directamente sobre las im√°genes.  
   Permite una implementaci√≥n sencilla y resultados razonables sin necesidad de entrenamiento adicional.


    coche11 ‚Üí ['MS66YOB']
    


    
![png](notebook_files/output_6_9.png)
    
 
    


   


# **Visualizaci√≥n de resultados**







    
![png](notebook_files/output_42_0.png)
    



    
![png](notebook_files/output_43_0.png)
    



3. **CNN Personalizada (PyTorch)**  
   Arquitectura desarrollada desde cero para la tarea de detecci√≥n y reconocimiento, utilizando un conjunto de datos reducido con fines experimentales.  
   Este enfoque permite un mayor control sobre las capas y los hiperpar√°metros, facilitando el an√°lisis comparativo del desempe√±o.



    
![png](notebook_files/output_46_1.png)
    



    
![png](notebook_files/output_46_2.png)
    




    
![png](notebook_files/output_46_4.png)
        




    

4. **YOLOv8 preentrenado (Ultralytics)**  
   Detector de objetos de √∫ltima generaci√≥n que ofrece un excelente equilibrio entre velocidad y precisi√≥n.  
   Se emplea un modelo preentrenado en COCO, ajustado para la detecci√≥n de matr√≠culas mediante transferencia de aprendizaje.




    
![png](notebook_files/output_49_4.png)
    


    Texto detectado: KLO1CA2555
    
    Procesando imagen: Cars1.jpg
    


    
![png](notebook_files/output_49_6.png)
    


    Texto detectado: PGoHN112
    
    Procesando imagen: Cars101.jpg
    

## üìä Metodolog√≠a y Evaluaci√≥n

El an√°lisis comparativo se realiza bajo tres dimensiones principales:

1. **Precisi√≥n y Recuperaci√≥n (Detecci√≥n de Matr√≠culas):**  
   Eval√∫a la capacidad del modelo para identificar correctamente las regiones que contienen matr√≠culas.

2. **Exactitud del OCR (Reconocimiento de Texto):**  
   Compara el texto reconocido con el texto real, considerando errores de car√°cter y palabras.

3. **Tiempo de Inferencia:**  
   Mide la eficiencia de procesamiento de cada modelo, en segundos por imagen.

El conjunto de pruebas incluye im√°genes con diferentes resoluciones, iluminaciones, √°ngulos y condiciones ambientales, con el prop√≥sito de simular escenarios reales.


# **Bibliografia**



*   **Dataset:** https://www.kaggle.com/datasets/andrewmvd/car-plate-detection/data
*   **Repositorio de ejemplo:** https://www.kaggle.com/code/semihberaterdoan/license-plate-recognition-with-yolov11m/notebook







